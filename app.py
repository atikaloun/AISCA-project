# app.py ‚Äî Interface AISCA enrichie (l√©ger + m√©tier)

import streamlit as st
import json
import os
from datetime import datetime

st.set_page_config(
    page_title="AISCA - Analyse S√©mantique des Comp√©tences",
    page_icon="üß†",
    layout="centered"
)

st.title("üß† AISCA")
st.subheader("Analyse S√©mantique pour la Cartographie des Comp√©tences et la Recommandation de M√©tiers")
st.markdown("---")

if "submitted" not in st.session_state:
    st.session_state.submitted = False

with st.form("questionnaire"):
    # === 1. Auto-√©valuation (Likert) ===
    st.header("1. Auto-√©valuation (√©chelle de 1 √† 5)")

    python_level = st.slider("Niveau en Python", 1, 5, 3)
    sql_level = st.slider("Ma√Ætrise de SQL (CTE, window functions)", 1, 5, 3)
    ml_level = st.slider("Machine Learning (r√©gression, classification, validation)", 1, 5, 3)
    dl_level = st.slider("Deep Learning (PyTorch/TensorFlow, CNN/Transformers)", 1, 5, 2)
    stats_level = st.slider("Statistiques (tests, biais/variance, probabilit√©s)", 1, 5, 3)
    mlops_level = st.slider("MLOps (Docker, d√©ploiement, monitoring)", 1, 5, 2)
    data_eng_level = st.slider("Data Engineering (ETL, Spark, pipelines)", 1, 5, 2)

    st.markdown("---")

    # === 2. Exp√©riences concr√®tes (texte libre) ===
    st.header("2. Exp√©riences concr√®tes")

    proj_python = st.text_area(
        "D√©crivez une exp√©rience o√π vous avez con√ßu ou optimis√© des flux de donn√©es (pipelines ETL) ou une architecture Big Data. Pr√©cisez les technologies utilis√©es (ex: Spark, Docker, SQL).",
        height=80
    )
    
    ml_pipeline = st.text_area(
        "D√©taillez un projet de Machine Learning ou d'IA que vous avez r√©alis√©. Expliquez le choix de vos algorithmes (ex: Transformers, CNN, r√©gressions).",
        height=80
    )
    
    dl_project = st.text_area(
        "D√©crivez comment vous avez d√©j√† transform√© des donn√©es brutes en tableaux de bord (dashboards) ou en analyses statistiques pour r√©pondre √† un besoin m√©tier. Avec quels outils ?.",
        height=80
    )
    
    data_pipeline = st.text_area(
        "Expliquez votre approche pour d√©finir une architecture globale de donn√©es ou pour piloter la strat√©gie d'un produit IA.",
        height=80
    )
    
    

    st.markdown("---")

    # === 3. Comp√©tences techniques ===
    st.header("3. Comp√©tences techniques")

    languages = st.multiselect(
        "Langages ma√Ætris√©s",
        ["Python", "SQL", "R", "Scala", "Java", "JavaScript", "Autre"],
        default=["Python", "SQL"]
    )
    
    frameworks = st.multiselect(
        "Frameworks / biblioth√®ques",
        ["Pandas", "Scikit-learn", "TensorFlow", "PyTorch", "Spark", "OpenCV", "Hugging Face", "Docker", "Airflow", "Kafka"]
    )
    
    used_genai = st.radio(
        "As-tu utilis√© des LLM ou APIs d‚ÄôIA g√©n√©rative ?",
        ("Oui", "Non")
    )
    if used_genai == "Oui":
        genai_tools = st.text_input("Lesquels ? (ex. : Gemini, OpenAI, Ollama)")
    else:
        genai_tools = ""

    st.markdown("---")

    # === 4. Orientation professionnelle ===
    st.header("4. R√¥les cibl√©s")

    target_roles = st.multiselect(
        "Quels r√¥les t‚Äôint√©ressent ?",
        [
            "Data Analyst", "Data Scientist", "Machine Learning Engineer", "AI Engineer",
            "NLP Engineer", "Computer Vision Engineer", "Data Engineer", "BigData Engineer",
            "Analytics Engineer", "BI Developer", "Statisticien", "Quantitative Analyst",
            "MLOps Engineer", "Data Architect", "AI Product Manager"
        ],
        default=["Data Scientist"]
    )

    # === Soumission ===
    submitted = st.form_submit_button("Analyser mes comp√©tences")

    if submitted:
        responses = {
            "timestamp": datetime.now().isoformat(),
            "likert": {
                "python": python_level,
                "sql": sql_level,
                "ml": ml_level,
                "dl": dl_level,
                "stats": stats_level,
                "mlops": mlops_level,
                "data_engineering": data_eng_level
            },
            "free_text": {
                "proj_python": proj_python,
                "ml_pipeline": ml_pipeline,
                "dl_project": dl_project,
                "data_pipeline": data_pipeline,
                "deploy_ml": deploy_ml
            },
            "technical": {
                "languages": languages,
                "frameworks": frameworks,
                "used_genai": used_genai,
                "genai_tools": genai_tools
            },
            "career": {
                "target_roles": target_roles
            }
        }

        os.makedirs("data", exist_ok=True)
        with open("data/latest_response.json", "w", encoding="utf-8") as f:
            json.dump(responses, f, indent=2, ensure_ascii=False)

        st.session_state.responses = responses
        st.session_state.submitted = True

# === Affichage apr√®s soumission ===
if st.session_state.submitted:
    st.success("‚úÖ Vos r√©ponses ont √©t√© enregistr√©es !")
    with st.expander("Voir vos r√©ponses brutes"):
        st.json(st.session_state.responses)