# app.py ‚Äî Interface AISCA enrichie (l√©ger + m√©tier)

import streamlit as st
import json
import os
from datetime import datetime

st.set_page_config(
    page_title="AISCA - Analyse S√©mantique des Comp√©tences",
    page_icon="üß†",
    layout="centered"
)

st.title("üß† AISCA")
st.subheader("Analyse S√©mantique pour la Cartographie des Comp√©tences et la Recommandation de M√©tiers")
st.markdown("---")

if "submitted" not in st.session_state:
    st.session_state.submitted = False

with st.form("questionnaire"):
    # === 1. Auto-√©valuation (Likert) ===
    st.header("1. Auto-√©valuation (√©chelle de 1 √† 5)")

    python_level = st.slider("Niveau en Python", 1, 5, 3)
    sql_level = st.slider("Ma√Ætrise de SQL (CTE, window functions)", 1, 5, 3)
    ml_level = st.slider("Machine Learning (r√©gression, classification, validation)", 1, 5, 3)
    dl_level = st.slider("Deep Learning (PyTorch/TensorFlow, CNN/Transformers)", 1, 5, 2)
    stats_level = st.slider("Statistiques (tests, biais/variance, probabilit√©s)", 1, 5, 3)
    mlops_level = st.slider("MLOps (Docker, d√©ploiement, monitoring)", 1, 5, 2)
    data_eng_level = st.slider("Data Engineering (ETL, Spark, pipelines)", 1, 5, 2)

    st.markdown("---")

    # === 2. Exp√©riences concr√®tes (texte libre) ===
    st.header("2. Exp√©riences concr√®tes")

    proj_python = st.text_area(
        "D√©cris un projet Python structur√© (modules, classes, tests).",
        height=80
    )
    
    ml_pipeline = st.text_area(
        "Explique ton pipeline ML de bout en bout (pr√©paration ‚Üí √©valuation).",
        height=80
    )
    
    dl_project = st.text_area(
        "As-tu entra√Æn√© un mod√®le profond (CNN, Transformer) ? D√©cris-le.",
        height=80
    )
    
    data_pipeline = st.text_area(
        "As-tu construit un pipeline de donn√©es (ETL, streaming) ? Raconte.",
        height=80
    )
    
    deploy_ml = st.text_area(
        "Comment as-tu d√©ploy√© un mod√®le en production ? (Docker, API, etc.)",
        height=80
    )

    st.markdown("---")

    # === 3. Comp√©tences techniques ===
    st.header("3. Comp√©tences techniques")

    languages = st.multiselect(
        "Langages ma√Ætris√©s",
        ["Python", "SQL", "R", "Scala", "Java", "JavaScript", "Autre"],
        default=["Python", "SQL"]
    )
    
    frameworks = st.multiselect(
        "Frameworks / biblioth√®ques",
        ["Pandas", "Scikit-learn", "TensorFlow", "PyTorch", "Spark", "OpenCV", "Hugging Face", "Docker", "Airflow", "Kafka"]
    )
    
    used_genai = st.radio(
        "As-tu utilis√© des LLM ou APIs d‚ÄôIA g√©n√©rative ?",
        ("Oui", "Non")
    )
    if used_genai == "Oui":
        genai_tools = st.text_input("Lesquels ? (ex. : Gemini, OpenAI, Ollama)")
    else:
        genai_tools = ""

    st.markdown("---")

    # === 4. Orientation professionnelle ===
    st.header("4. R√¥les cibl√©s")

    target_roles = st.multiselect(
        "Quels r√¥les t‚Äôint√©ressent ?",
        [
            "Data Analyst", "Data Scientist", "Machine Learning Engineer", "AI Engineer",
            "NLP Engineer", "Computer Vision Engineer", "Data Engineer", "BigData Engineer",
            "Analytics Engineer", "BI Developer", "Statisticien", "Quantitative Analyst",
            "MLOps Engineer", "Data Architect", "AI Product Manager"
        ],
        default=["Data Scientist"]
    )

    # === Soumission ===
    submitted = st.form_submit_button("Analyser mes comp√©tences")

    if submitted:
        responses = {
            "timestamp": datetime.now().isoformat(),
            "likert": {
                "python": python_level,
                "sql": sql_level,
                "ml": ml_level,
                "dl": dl_level,
                "stats": stats_level,
                "mlops": mlops_level,
                "data_engineering": data_eng_level
            },
            "free_text": {
                "proj_python": proj_python,
                "ml_pipeline": ml_pipeline,
                "dl_project": dl_project,
                "data_pipeline": data_pipeline,
                "deploy_ml": deploy_ml
            },
            "technical": {
                "languages": languages,
                "frameworks": frameworks,
                "used_genai": used_genai,
                "genai_tools": genai_tools
            },
            "career": {
                "target_roles": target_roles
            }
        }

        os.makedirs("data", exist_ok=True)
        with open("data/latest_response.json", "w", encoding="utf-8") as f:
            json.dump(responses, f, indent=2, ensure_ascii=False)

        st.session_state.responses = responses
        st.session_state.submitted = True

# === Affichage apr√®s soumission ===
if st.session_state.submitted:
    st.success("‚úÖ Vos r√©ponses ont √©t√© enregistr√©es !")
    with st.expander("Voir vos r√©ponses brutes"):
        st.json(st.session_state.responses)